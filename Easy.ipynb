{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb6fc68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder.appName('deep') \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aab86f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://g01.itversity.com:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>deep</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f7a9cc73438>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f179731c",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = 'id int, date date, cust_id int, status string'\n",
    "df = spark.read.csv('/orders/orders_1gb.csv',schema=schema,mode='permissive')\n",
    "df = df.distinct()\n",
    "df.coalesce(1).write.mode('overwrite').format('parquet').option('path','/user/orders_deep/').save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfecbcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+---------+\n",
      "|col1|col2|   result|\n",
      "+----+----+---------+\n",
      "|   a|  aa|   [1, 2]|\n",
      "|   b|  bb|[5, 4, 3]|\n",
      "+----+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lt = [['a','aa',1],['a','aa',2],['b','bb',5],['b','bb',4],['b','bb',3]]\n",
    "df = spark.sparkContext.parallelize(lt).toDF(['col1','col2','col3'])\n",
    "# df = spark.createDataFrame(lt).toDF(*['col1','col2','col3'])\n",
    "df = df.groupBy('col1','col2').agg(\n",
    "    collect_list(col('col3')).alias('result')\n",
    ").orderBy(col('col1').asc(),col('col2').asc())\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ff3a3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| id|eid|\n",
      "+---+---+\n",
      "|101|101|\n",
      "|101|102|\n",
      "|101|103|\n",
      "|102|104|\n",
      "|102|105|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lt = [{'id':101,'eid':[101,102,103]},{'id':102,'eid':[104,105]}]\n",
    "df = spark.sparkContext.parallelize(lt).toDF()\n",
    "df = df.withColumn('eid',explode(col('eid'))).select('id','eid')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f9a98c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+-------+-----------+\n",
      "|type|      date|avg_amt|max_avg_amt|\n",
      "+----+----------+-------+-----------+\n",
      "|AAPL|2023-01-01|  150.0|      155.0|\n",
      "|AAPL|2023-01-02|  155.0|      155.0|\n",
      "|GOOG|2023-01-01| 2500.0|     2550.0|\n",
      "|GOOG|2023-01-02| 2550.0|     2550.0|\n",
      "|MSFT|2023-01-01|  300.0|      310.0|\n",
      "|MSFT|2023-01-02|  310.0|      310.0|\n",
      "+----+----------+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(\"2023-01-01\", \"AAPL\", 150.00), (\"2023-01-02\", \"AAPL\",\n",
    "155.00), (\"2023-01-01\", \"GOOG\", 2500.00), (\"2023-01-02\", \"GOOG\",\n",
    "2550.00), (\"2023-01-01\", \"MSFT\", 300.00), (\"2023-01-02\", \"MSFT\",\n",
    "310.00)]\n",
    "\n",
    "df = spark.createDataFrame(data,['date','type','amt'])\n",
    "df = df.withColumn('date',to_date(col('date')))\n",
    "df = df.groupby('type','date').agg(\n",
    "    mean(col('amt')).alias('avg_amt')\n",
    ")\n",
    "df = df.withColumn('max_avg_amt',expr('max(avg_amt) over(partition by type)'))\n",
    "df = df.sort(['type','date'],asc=[True,True])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b5024e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "|date|cumm_sum|\n",
      "+----+--------+\n",
      "|   5|   13000|\n",
      "|   7|    1250|\n",
      "|   6|   10000|\n",
      "+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "(3000, \"22-may\"),\n",
    "(5000, \"23-may\"),\n",
    "(5000, \"25-may\"),\n",
    "(10000, \"22-june\"),\n",
    "(1250, \"03-july\")\n",
    "]\n",
    "df = spark.createDataFrame(data,['salary','date'])\n",
    "df = df.withColumn('date',month(to_date(concat(col('date'),lit('-2025')),format='dd-MMMM-yyyy')))\n",
    "df = df.groupby('date').agg(sum(col('salary')).alias('cumm_sum'))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aeef5ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+\n",
      "|        Name|Age|\n",
      "+------------+---+\n",
      "| John,Cleark| 30|\n",
      "|   Sumit,Sen| 31|\n",
      "|Brayan,gomez| 25|\n",
      "+------------+---+\n",
      "\n",
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = '''Name~|Age\n",
    "Brayan,gomez~|25\n",
    "John,Cleark~|30\n",
    "Sumit,Sen~|31\n",
    "'''\n",
    "\n",
    "rdd = spark.sparkContext.parallelize(s.splitlines()[1:])\n",
    "rdd = rdd.map(lambda x: x.split('~|')).map(lambda x: x[0]+'|'+x[1])\n",
    "rdd.saveAsTextFile('/user/data1/')\n",
    "\n",
    "df = spark.read.csv('/user/data1/',sep='|').toDF(*['Name','Age'])\n",
    "df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30c2a382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|employee_id|count|\n",
      "+-----------+-----+\n",
      "|          4|    1|\n",
      "|          5|    2|\n",
      "|          6|    2|\n",
      "|          1|    3|\n",
      "|          2|    3|\n",
      "|          3|    3|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lt = [[1,8],[2,8],[3,8],[4,7],[5,9],[6,9]]\n",
    "df = spark.sparkContext.parallelize(lt).toDF(['employee_id','team_id'])\n",
    "#method 1\n",
    "temp = df.groupby('team_id').count()\n",
    "final = df.join(temp,df['team_id']==temp['team_id'])\n",
    "final = final.select('employee_id','count')\n",
    "\n",
    "#metohd 2\n",
    "df = df.groupby('team_id').agg(\n",
    "    collect_list(col('employee_id')).alias('collect')\n",
    ").withColumn('employee_id',explode('collect')).select('employee_id',size(col('collect')).alias('count'))\n",
    "final.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
